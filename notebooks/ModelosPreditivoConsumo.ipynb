{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Supervisionado\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Um modelo supervisionado é responsável por receber dados rotulados e desenvolver um algoritmo que é capaz de prever e classificar dados. Os modelos supervisionados se dividem em duas vertentes: Classificação e regressão. A classificação, como o nome já diz, é responsável por classificar e criar grupos de dados com características semelhantes. Já a regressão é utilizada para fazer previsões e avaliar variáveis isoladas. [(Alteryx, 2023)](https://www.alteryx.com/pt-br/glossary/supervised-vs-unsupervised-learning)\n",
    "\n",
    "#### Organização dos dados:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Para o modelo supervisionado, organizamos os dados da seguinte forma: 80% do banco de dados voltado para o treinamento e 20% voltado ao teste do modelo. Utilizamos essa disposição dos dados, pois assim temos uma boa quantidade de dados para o treinamento e uma boa margem para teste, além de previnirmos o *overfitting*, já que uma parte dos dados está separada especificamente para o teste do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; O presente _notebook_ teve a finalidade de testar possíveis modelos preditivos que pudessem prever padrões de consumo dos clientes da base de dados com base no cosumo dos meses anteriores. Para isso, foram feitas adequações necessárias nos valores e testes consecutivos de diferentes modelos para então, escolher qual o mais satisfatório. Em decorrência dessa análise, as métricas mais satisfatórias vieram do modelo _**Regressão (SVR)**_ do _Scikit-Learn_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Importação das bibliotecas necessárias para análise e modelagem dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, f_regression\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import uniform, randint\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import make_blobs\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datas\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Importação dos dados que serão utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_atualizado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de features\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Seleção dos dados do cliente com `clientCode` 683 e `clientIndex` 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega o client com o clientcode 2 e o clientindex 0\n",
    "df_client = df[(df['clientCode'] == 683) & (df['clientIndex'] == 0)]\n",
    "df_client.head(5)\n",
    "\n",
    "# df_client = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Com o objetivo de visualizar a correlação entre as features para a construção do modelo preditivo, foi realizada uma matriz de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client['date'] = pd.to_datetime(df_client['date'])\n",
    "\n",
    "# Verificar a correlação entre as variáveis\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_client.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()\n",
    "\n",
    "# Verificar a distribuição das variáveis\n",
    "df.hist(bins=30, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; A análise do gráfico acima revela que, em geral, as variáveis têm pouca correlação, como observado na coluna 'hora', que mostra uma correlação baixa, esse fato sugere que sua influência no comportamento do consumidor pode ser limitada ou não linear. Por outro lado, features como 'mês' e 'data' apresentam correlações significativas que podem ser exploradas para uma melhor compreensão do comportamento do cliente e suas sazonalidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Considerando que não é lógico prever o consumo utilizando valores negativos, que representam possíveis anomalias, as linhas com gastos negativos foram excluídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apaga todas as linhas com gasto 0\n",
    "df_client = df_client[df_client['gasto'] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; A célula abaixo comprova que todos os valores negativos foram removidos do *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = df_client[df_client['gasto'] < 0]\n",
    "teste.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Cálculo da média e desvio padrão do consumo e remoção de valores fora do desvio padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_client['gasto'].mean()\n",
    "desvio = df_client['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_client = df_client[df_client['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_client = df_client[df_client['gasto'] > minimo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Separação dos dados em variáveis independentes (X) e variável dependente (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar em recursos (X) e alvo (y)\n",
    "X = df_client[['dia_da_semana', 'mes', 'feriado', 'Temp. Ins. (C)',\n",
    "       'Temp. Max. (C)', 'Temp. Min. (C)', 'Umi. Ins. (%)', 'Umi. Max. (%)',\n",
    "       'Umi. Min. (%)', 'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)',\n",
    "       'Pto Orvalho Min. (C)', 'Pressao Ins. (hPa)', 'Pressao Max. (hPa)',\n",
    "       'Pressao Min. (hPa)', 'Vel. Vento (m/s)', 'Dir. Vento (°)',\n",
    "       'Raj. Vento (m/s)', 'Chuva (mm)']]\n",
    "\n",
    "y = df_client['gasto']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; O gráfico plotado abaixo representa o gasto por dia da semana do cliente 683, conforme especificado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico gasto x dia da semana\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_client['dia_da_semana'] = df_client['dia_da_semana'].replace({0: 'Segunda', 1: 'Terça', 2: 'Quarta', 3: 'Quinta', 4: 'Sexta', 5: 'Sabado', 6: 'Domingo'})\n",
    "sns.lineplot(x='dia_da_semana', y='gasto', data=df_client)\n",
    "plt.title('Consumo de gás de um cliente por dia da semana - ClientCode 683')\n",
    "plt.xlabel('Dia da Semana')\n",
    "plt.ylabel('Consumo de gás (m3 - metros cúbicos)')\n",
    "plt.legend(['Média de consumo de gás', 'Variância de consumo de gás'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; A análise do gráfico acima revela uma alta variabilidade no consumo de gás durante os dias da semana. Nesse sentido, em um mesmo dia da semana, pode haver tanto um consumo elevado quanto um consumo baixo. Nesse sentido, esse fato implica que, ao calcular a média desses consumos para a construção do modelo, a acurácia provavelmente será reduzida. Portanto, pode-se concluir que é necessário uma quantidade maior de dados para construir uma predição mais precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do modelo\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Separação dos dados base para testar o modelo, bem como seus parâmetros e especificidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o conjunto de dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo - SVR \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Para mitigação de possíveis erros e melhor acurácia, foram testados outros modelos para analisar se os _outputs_ iriam diferir drasticamente um do outro. O modelo **SVR** foi um desses. O mesmo é uma variação do _**Support Vector Machine (SVM)**_, usada para regressão em vez de classificação. Ele busca encontrar uma função que se ajuste aos dados, minimizando o erro, mas de uma forma que seja robusta a outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSvr = make_pipeline(SVR(kernel='rbf', C=10000, gamma=0.01, epsilon=0.005, tol=1e-5))\n",
    "\n",
    "modeloSvr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Definição e ajuste de hiperparâmetros do modelo SVR usando RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o modelo SVR\n",
    "svr = SVR()\n",
    "\n",
    "# Definindo os hiperparâmetros a serem testados\n",
    "param_distributions = {\n",
    "    'C': uniform(0.01, 10000),            # Busca valores contínuos entre 0.1 e 100\n",
    "    'epsilon': uniform(0.001, 1),        # Busca valores de epsilon entre 0.01 e 1\n",
    "    'kernel': ['rbf'], # Busca entre os kernels mais comuns\n",
    "    'gamma': uniform(0.01, 1000)          # Define como será calculado o gamma\n",
    "}\n",
    "\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(svr, param_distributions, n_iter=50, cv=5, \n",
    "                                   scoring='neg_mean_squared_error', random_state=42, verbose=1)\n",
    "\n",
    "# Treinando o RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor conjunto de parâmetros\n",
    "print(\"Melhores parâmetros: \", random_search.best_params_)\n",
    "\n",
    "# Avaliando o desempenho no conjunto de teste\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculando as métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE: \", mse)\n",
    "print(\"MAE: \", mae)\n",
    "print(\"R2: \", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsão dos valores de teste usando o modelo SVR e impressão dos primeiros 10 resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_svr = modeloSvr.predict(X_test)\n",
    "\n",
    "print(y_pred_test_svr[0:10])\n",
    "\n",
    "print(y_test[0:10] - y_pred_test_svr[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; A principal métrica para medir o modelo é o _**Mean Absolute Error (MAE)**_, ou Erro Médio Absoluto. Consiste no processo de medir a precisão de um modelo de previsão, calculando a média dos erros absolutos entre os valores preditos e os valores reais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de treino: {mean_absolute_error(y_train, modeloSvr.predict(X_train))}')\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, modeloSvr.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Como auxiliares nas métricas, também tem-se o _**Mean Squared Error (MSE)**_ e o _**Root Mean Squared Error (RMSE)**_ que também são comuns para avaliar a precisão de modelos de regressão. A principal diferença, nesse caso, é que o **MSE** e o **RMSE** penalizam erros maiores de maneira mais severa, já que os **erros são elevados ao quadrado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de treino: {mean_squared_error(y_train, modeloSvr.predict(X_train))}')\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, modeloSvr.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de treino: {np.sqrt(mean_squared_error(y_train, modeloSvr.predict(X_train)))}')\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, modeloSvr.predict(X_test)))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico para percepção visual do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Para análise mais minuciosa, foi _plotado_ um gráfico de dispersão para identificar os padrões dos valores previstos em relação aos valores reais ao qual o modelo foi treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões para o conjunto de treino\n",
    "y_train_pred = modeloSvr.predict(X_train)\n",
    "\n",
    "# Plotando os valores reais vs previstos no conjunto de treino\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gráfico dos valores reais (y_train) vs valores previstos\n",
    "plt.scatter(np.arange(len(y_train)), y_train, color='blue', label='Valores Reais')\n",
    "plt.scatter(np.arange(len(y_train_pred)), y_train_pred, color='red', alpha=0.6, label='Valores Previstos')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos (Treino)')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Gasto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Gráfico de análise da regressão e como os resultados se relacionam com a **Perfeita Correspondência**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testa o modelo com o conjunto de teste\n",
    "y_pred = modeloSvr.predict(X_test)\n",
    "\n",
    "# Previsões para o conjunto de teste\n",
    "y_test_pred = modeloSvr.predict(X_test)\n",
    "\n",
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, y_test_pred, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Adicionando uma linha diagonal (y=x), que representa a \"perfeita correspondência\"\n",
    "limite = [min(y_test.min(), y_test_pred.min()), max(y_test.max(), y_test_pred.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "plt.title('Consumo Previsto vs Consumo Real (Teste)')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olsmod = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "olsmod.fit(X_train, y_train)\n",
    "\n",
    "olsres = olsmod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Verifica a distância do dado previsto com o dado real - tendo como base os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = olsres.predict(X_test)\n",
    "\n",
    "print(y_pred_test[0:10])\n",
    "\n",
    "print(y_test[0:10] - y_pred_test[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; A principal métrica para medir o modelo é o _**Mean Absolute Error (MAE)**_, ou Erro Médio Absoluto. Consiste no processo de medir a precisão de um modelo de previsão, calculando a média dos erros absolutos entre os valores preditos e os valores reais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de treino: {mean_absolute_error(y_train, olsres.predict(X_train))}')\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, olsres.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Como auxiliares nas métricas, também tem-se o _**Mean Squared Error (MSE)**_ e o _**Root Mean Squared Error (RMSE)**_ que também são comuns para avaliar a precisão de modelos de regressão. A principal diferença, nesse caso, é que o **MSE** e o **RMSE** penalizam erros maiores de maneira mais severa, já que os **erros são elevados ao quadrado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de treino: {mean_squared_error(y_train, olsres.predict(X_train))}')\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, olsres.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de treino: {np.sqrt(mean_squared_error(y_train, olsres.predict(X_train)))}')\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, olsres.predict(X_test)))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Quantidade de amostras disponíveis que o modelo ainda não viu para as treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de amostras de treino\n",
    "n = X_train.shape[0]\n",
    "\n",
    "print(f'Quantidade de amostras de treino: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico para percepção visual do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Para análise mais minuciosa, foi _plotado_ um gráfico de dispersão para identificar os padrões dos valores previstos em relação aos valores reais ao qual o modelo foi treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões para o conjunto de treino\n",
    "y_train_pred = olsres.predict(X_train)\n",
    "\n",
    "# Plotando os valores reais vs previstos no conjunto de treino\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gráfico dos valores reais (y_train) vs valores previstos\n",
    "plt.scatter(np.arange(len(y_train)), y_train, color='blue', label='Valores Reais')\n",
    "plt.scatter(np.arange(len(y_train_pred)), y_train_pred, color='red', alpha=0.6, label='Valores Previstos')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos (Treino)')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Gasto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Gráfico de análise da regressão e como os resultados se relacionam com a **Perfeita Correspondência**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testa o modelo com o conjunto de teste\n",
    "y_pred = olsres.predict(X_test)\n",
    "\n",
    "# Previsões para o conjunto de teste\n",
    "y_test_pred = olsres.predict(X_test)\n",
    "\n",
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, y_test_pred, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Adicionando uma linha diagonal (y=x), que representa a \"perfeita correspondência\"\n",
    "limite = [min(y_test.min(), y_test_pred.min()), max(y_test.max(), y_test_pred.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "plt.title('Consumo Previsto vs Consumo Real (Teste)')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões para o conjunto de treino\n",
    "y_test_pred = olsres.predict(X_test)\n",
    "\n",
    "# Plotando os valores reais vs previstos no conjunto de treino\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gráfico dos valores reais (y_test) vs valores previstos\n",
    "plt.scatter(np.arange(len(y_test)), y_test, color='blue', label='Valores Reais')\n",
    "plt.scatter(np.arange(len(y_test_pred)), y_test_pred, color='red', alpha=0.6, label='Valores Previstos')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos (Teste)')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Gasto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacao de modelos SVR x RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Gráfico de comparação entre os modelos SVR e RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico de comparacao entre os modelos de regressao svr e random forest\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='Random Forest')\n",
    "plt.scatter(y_test, modeloSvr.predict(X_test), color='red', alpha=0.6, label='SVR')\n",
    "plt.plot(y_test, y_test, color='blue', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "plt.title('Comparação entre Random Forest e SVR - Client Code 683')\n",
    "plt.xlabel('Gasto Real')\n",
    "plt.ylabel('Gasto Previsto')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Métricas de avaliação dos modelos, como MAE, MSE e RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparacao entre os modelos de regressao svr e random forest\n",
    "\n",
    "# R2, MAE, MSE, RMSE\n",
    "\n",
    "# Random Forest\n",
    "r2_rf = r2_score(y_test, y_pred)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred)\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "# SVR\n",
    "r2_svr = r2_score(y_test, modeloSvr.predict(X_test))\n",
    "mae_svr = mean_absolute_error(y_test, modeloSvr.predict(X_test))\n",
    "mse_svr = mean_squared_error(y_test, modeloSvr.predict(X_test))\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "\n",
    "# Criando um DataFrame com as métricas\n",
    "df_metricas = pd.DataFrame({\n",
    "    'Random Forest': [r2_rf, mae_rf, mse_rf, rmse_rf],\n",
    "    'SVR': [r2_svr, mae_svr, mse_svr, rmse_svr]\n",
    "}, index=['R2', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do dataset para o Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Ao realizarmos as predições de consumo por cada cliente, a equipe decidiu clusterizá-los com base em suas especificidades e perfil de consumo. Para isso, fez-se necessário gerar um novo modelo não-supervisionado (_**Kmeans**_) para encontrar padrões e proximidade entre os clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Leitura abaixo do _**csv**_ atualizado com os dados metereológicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../data/df_atualizado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Leitura abaixo do _**csv**_ com os dados IPCA de Porto Alegre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_porto_alegre = pd.read_csv('../data/porto_alegre_dados_finalizados.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Substituição da coluna 'Mês' por 'mes' para que mantenha o padrão anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_porto_alegre = df_porto_alegre.rename(columns={'Mês': 'mes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Merge de ambos os _**csv's**_ para agregar mais festures ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_1, df_porto_alegre, on='mes', how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Drop da coluna 'date' pois já existem colunas de mês, hora e dia da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns = ['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Renomeação do nome de algumas colunas para maneter o padrão anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'1.Alimentação e bebidas': 'alimentacao/bebidas', '2.AHabitação': 'habitacao', '3.Artigos de residência': 'artigo-de-residencia', '4.Vestuários': 'vestuario', '5.Transportes': 'transportes' , '6.Saúde e cuidados pessoais': 'saude/cuidados', '7.Despesas pessoais': 'despesas-pessoais', '8.Educação': 'educacao', '9.Comunicação': 'comunicacao', 'Índice geral': 'indice-geral'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Criação de uma função para remover _outliers_ com base e desvios padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, std_devs=3):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std_dev = np.std(data, axis=0)\n",
    "    lower_bound = mean - std_devs * std_dev\n",
    "    upper_bound = mean + std_devs * std_dev\n",
    "    mask = np.all((data >= lower_bound) & (data <= upper_bound), axis=1)\n",
    "    return data[mask], mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Exclusão dos valores negativos encontrados na coluna de gastos pois, possivelmente, se tratam de anomalias e não são relevantes para a predição do consumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativos = df[df['gasto'] < 0]\n",
    "print(f\"Valores negativos encontrados:\\n{negativos}\")\n",
    "\n",
    "df = df[df['gasto'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Plotagem do gráfico do **Método do Cotovelo** para identificar a melhor quantidade de clusters que o modelo deve apresentar e se estruturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "sse = []\n",
    "\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, sse, marker='o')\n",
    "plt.title('Método do Cotovelo')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Soma das Distâncias Quadráticas Dentro dos Clusters (SSE)')\n",
    "plt.xticks(K)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Pela curva não ser tão brusca, houve a dúvida entre 4 ou 5 _clusters_ que, posteriormente, seriam testados no código do _**Kmeans**_ e plotados em um gráfico _**PCA**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Geração do Modelo _**Kmeans**_ com _clusters_ indo em uma faixa de 2-6 e plotagem de gráficos 2D e 3D para melhor visualização da separação de cada grupo encontrado e como o mesmo se comporta no espaço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_range = range(2, 7)\n",
    "rotation_angles = range(0, 360, 90)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df.drop(columns=['date', 'clientCode', 'clientIndex']))\n",
    "\n",
    "df_scaled_no_outliers, mask = remove_outliers(df_scaled, std_devs=3)\n",
    "\n",
    "for clusters in cluster_range:\n",
    "    \n",
    "    km = KMeans(n_clusters=clusters, random_state=42)\n",
    "    y_predict_no_outliers = km.fit_predict(df_scaled_no_outliers)\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    df_pca_3d = pca.fit_transform(df_scaled_no_outliers)\n",
    "\n",
    "    pca_2d = PCA(n_components=2)\n",
    "    df_pca_2d = pca_2d.fit_transform(df_scaled_no_outliers)\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    ax2 = fig.add_subplot(122)\n",
    "\n",
    "    sns.scatterplot(x=df_pca_2d[:, 0], y=df_pca_2d[:, 1], hue=y_predict_no_outliers, s=100, alpha=0.75, \n",
    "                    palette=\"Set1\", edgecolor='white', linewidth=0.8, ax=ax2)\n",
    "\n",
    "    ax2.set_title(f\"2D Clusters: {clusters}\")\n",
    "    ax2.set_xlabel(\"Componente Principal 1\")\n",
    "    ax2.set_ylabel(\"Componente Principal 2\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    for angle in rotation_angles:\n",
    "        \n",
    "        fig_3d = plt.figure(figsize=(14, 7))\n",
    "        ax = fig_3d.add_subplot(111, projection='3d')\n",
    "\n",
    "        scatter_3d = ax.scatter(df_pca_3d[:, 0], df_pca_3d[:, 1], df_pca_3d[:, 2], \n",
    "                                c=y_predict_no_outliers, s=100, alpha=0.75, cmap='Set1', linewidth=0.8)\n",
    "\n",
    "        ax.set_title(f\"3D Clusters: {clusters}, Ângulo: {angle}°\")\n",
    "        ax.set_xlabel(\"Componente Principal 1\")\n",
    "        ax.set_ylabel(\"Componente Principal 2\")\n",
    "        ax.set_zlabel(\"Componente Principal 3\")\n",
    "\n",
    "        ax.view_init(elev=30, azim=angle)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "df['cluster'] = 0  \n",
    "\n",
    "for clusters in cluster_range:\n",
    "    km = KMeans(n_clusters=clusters, random_state=42)\n",
    "    y_predict_no_outliers = km.fit_predict(df_scaled_no_outliers)\n",
    "\n",
    "    \n",
    "    if clusters == 5:\n",
    "        df.loc[mask, 'cluster'] = y_predict_no_outliers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Com base nos resultados, o número de _clusters_ escolhido foi: **5**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Abaixo, estatísticas de gasto por cluster para identificar comportamento de consumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfil_consumo = df.groupby('cluster')['gasto'].agg(['mean', 'median', 'std', 'min', 'max', 'count']).reset_index()\n",
    "\n",
    "print(perfil_consumo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cluster 0**\n",
    "O Cluster 0 tem uma média de consumo de 3,63 m³ e uma mediana de 0,40 m³, o que sugere que a maioria dos clientes consome muito pouco. No entanto, o desvio padrão extremamente alto de 192,99 m³ revela uma grande variação, causada por outliers com valores de consumo máximos de até 39.382,09 m³. Isso indica que, embora a maioria consuma pouco, alguns clientes têm um consumo excepcionalmente elevado, aumentando a variabilidade do grupo.\n",
    "\n",
    "**Cluster 1**\n",
    "O Cluster 1 apresenta uma média de consumo de 0,83 m³ e uma mediana de 0,41 m³, indicando também um padrão de consumo baixo. O desvio padrão de 3,30 m³ sugere que há uma variabilidade menor do que no Cluster 0, mas ainda existem alguns consumidores com consumo bem maior, com um máximo de 277,71 m³. A maioria dos clientes está concentrada em pequenos consumos, mas ainda há outliers que elevam a variabilidade.\n",
    "\n",
    "**Cluster 2**\n",
    "O Cluster 2 possui uma média de consumo de 0,73 m³ e uma mediana de 0,25 m³, destacando um perfil de consumo ainda mais baixo. O desvio padrão de 3,19 m³ reflete uma variabilidade razoável, com o valor máximo chegando a 211,54 m³. Este cluster é formado majoritariamente por consumidores de baixo consumo, mas há alguns com consumos maiores.\n",
    "\n",
    "**Cluster 3**\n",
    "O Cluster 3 tem uma média de consumo de 0,80 m³ e uma mediana de 0,24 m³, com uma variabilidade (desvio padrão de 3,15 m³) um pouco menor, mas ainda relevante. Alguns clientes têm consumo de até 158,08 m³, demonstrando a presença de outliers, embora a maioria mantenha um padrão de consumo reduzido.\n",
    "\n",
    "**Cluster 4**\n",
    "O Cluster 4 tem uma média de 0,74 m³ e uma mediana de 0,30 m³, e é o cluster com a menor variabilidade (desvio padrão de 2,93 m³). O consumo máximo é de 156,52 m³, indicando menos casos de consumo extremo comparado aos outros clusters. Aqui, o consumo é mais concentrado em valores baixos, com menos outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Por conta do _dataset_ ser por hora, há clientes com mais de um linha de dado e que, por conta da variação de consumo, assumia mais de um _cluster_. Para corrgir esse erro, agrupamos os _clusters_ por _clientCode_ e mudamos o valor para a moda de _cluster_ que mais apareceu naquele _clientCodeCode_ específico. Assim, cada cliente correspondia à apenas um grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_mais_frequente = df.groupby('clientCode')['cluster'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "df['cluster'] = df['clientCode'].map(cluster_mais_frequente)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Contagem da quantidade de linhas com cada _cluster_ específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ones = df['cluster'].value_counts()[3]\n",
    "print(f\"A quantidade de números x é: {count_ones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Criação de um novo _dataframe_ com todas novas features e cada cliente rotulado por seu respectivo _cluster_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/df_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo preditivo para previsão de consumo com base nos clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_cluster.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento prévio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Tendo em vista que cada tipo de modelo exige um tratamento de dados específico, para o presente modelo foram removidas as colunas 'medidor' e 'gasto_por_hora'. Nesse sentido, optou-se por utilizar apenas a coluna 'gasto' no treinamento, já que ambas se referem ao consumo. Assim, o valor de 'gasto' é obtido pela multiplicação do pulseCount pelo gain de cada medição, enquanto 'gasto_por_hora' representa o consumo por hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['medidor','gasto_por_hora', 'hora'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Além disso, foram removidos os valores negativos presentes no *DataFrame*, garantindo que tais valores não interfiram no processo de treinamento do modelo. Uma vez que a presença de dados negativos poderia causar distorções nos resultados, especialmente em variáveis que deveriam representar quantidades positivas, como consumo, que naturalmente não assumem valores abaixo de zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gasto'] >= 0]\n",
    "len(df[df['gasto'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Com o objetivo de aprimorar o desempenho dos modelos, decidiu-se dividir o *DataFrame* original em cinco subconjuntos, cada um correspondente a um cluster gerado pelo algoritmo K-means, que agrupou os dados de acordo com o perfil de consumo. Dessa forma, cada subconjunto será utilizado para treinar um modelo específico, o que permitirá uma abordagem mais personalizada para cada grupo de perfis de consumo. Assim, podendo gerar melhores desempenhos nas previsões ao capturar as características específicas de cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['cluster'] == 0]\n",
    "df_1 = df[df['cluster'] == 1]\n",
    "df_2 = df[df['cluster'] == 2]\n",
    "df_3 = df[df['cluster'] == 3]\n",
    "df_4 = df[df['cluster'] == 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('../data/df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Por fim, os outliers foram removidos ao identificar valores de consumo de gás que se desviavam excessivamente da média, utilizando o desvio padrão para definir os limites superior e inferior. Dessa forma, os dados que ultrapassavam esses limites (valores muito acima ou abaixo da média) foram eliminados, mantendo apenas os consumos dentro de um desvio padrão da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_0['gasto'].mean()\n",
    "desvio = df_0['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_0 = df_0[df_0['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_0 = df_0[df_0['gasto'] > minimo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_1['gasto'].mean()\n",
    "desvio = df_1['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_1 = df_1[df_1['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_1 = df_1[df_1['gasto'] > minimo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_2['gasto'].mean()\n",
    "desvio = df_2['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_2 = df_2[df_2['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_2 = df_2[df_2['gasto'] > minimo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_3['gasto'].mean()\n",
    "desvio = df_3['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_3 = df_3[df_3['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_3 = df_3[df_3['gasto'] > minimo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o consumo medio do cliente e o desvio padrao\n",
    "media = df_4['gasto'].mean()\n",
    "desvio = df_4['gasto'].std()\n",
    "\n",
    "# Remove os consumos que estao fora do desvio padrao\n",
    "\n",
    "maximo = media + (1*desvio)\n",
    "df_4 = df_4[df_4['gasto'] < maximo]\n",
    "\n",
    "minimo = media - (1*desvio)\n",
    "df_4 = df_4[df_4['gasto'] > minimo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo do cluster 0 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo sem os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_0.drop(columns=['gasto','date'])  \n",
    "y = df_0['gasto'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model_0 = XGBRegressor(objective='reg:pseudohubererror', random_state=123)\n",
    "\n",
    "model_0.fit(X_train, y_train)\n",
    "\n",
    "predictions = model_0.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da perfomace do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 0')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model_0, 'xgb_regressor_model0.pkl')\n",
    "# Load the model later (when needed)\n",
    "loaded_model_0 = joblib.load('xgb_regressor_model0.pkl')\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model_0.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo do cluster 1 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo sem os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_1.drop(columns=['gasto','date'])  \n",
    "y = df_1['gasto'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model_1 = XGBRegressor(objective='reg:pseudohubererror', random_state=123)\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "predictions = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da perfomace do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 1')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model_1, 'xgb_regressor_model1.pkl')\n",
    "# Load the model later (when needed)\n",
    "loaded_model_1 = joblib.load('xgb_regressor_model1.pkl')\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo do cluster 2 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo sem os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop(columns=['gasto','date'])  \n",
    "y = df_2['gasto'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model_2 = XGBRegressor(objective='reg:pseudohubererror', random_state=123)\n",
    "\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "predictions = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da perfomace do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 2')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model_2, 'xgb_regressor_model2.pkl')\n",
    "# Load the model later (when needed)\n",
    "loaded_model_2 = joblib.load('xgb_regressor_model2.pkl')\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo do cluster 3 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo sem os hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Para uma primeira análise, utilizou o XGBoost Regressor que é um algoritmo de aprendizado supervisionado baseado em árvores de decisão. Nesse sentido, ele faz parte de uma técnica chamada boosting, na qual várias árvores de decisão são criadas de maneira sequencial. Assim, cada nova árvore tenta corrigir os erros das anteriores, melhorando gradualmente a precisão do modelo. Além disso, nesta etapa inicial, os hiperparâmetros não foram ajustados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_3.drop(columns=['gasto','date'])  \n",
    "y = df_3['gasto'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model_3 = XGBRegressor(objective='reg:pseudohubererror', random_state=123)\n",
    "\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "predictions = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da perfomace do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Com a finalidade de obsersar a análise e a performace do modelo, plotou-se uma gráfico de dispersão que compara os valores reais (y_test) com os valores previstos pelo modelo (predictions). Além disso, ele adiciona diversas linhas de referência para visualização de correspondências entre os valores. Com isso, esse tipo de gráfico é uma ferramenta visual para identificar o quão bem o modelo se ajusta aos dados observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 3')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; O gráfico mencionado foi gerado com base no modelo de cluster 3, e sua análise permite observar que a maioria dos dados se concentra nas regiões delimitadas pelas linhas de referência de 75% e 50%. Dessa forma, esse fato indica que o modelo está fazendo previsões consistentes, com uma certa aproximação em relação aos valores reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Foram utilizadas as métricas MAE, MSE, RMSE e R² para avaliar a performance de modelo. Segue abaixo os resultados obtidos nesta primeira análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Com o objetivo de melhorar a performance do modelo, foi realizado um processo de otimização de hiperparâmetros utilizando a biblioteca Optuna. Essa biblioteca permite realizar uma busca eficiente pelos melhores hiperparâmetros com o objetivo de identificar as combinações que oferecem os melhores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:pseudohubererror\",  # Mantendo o mesmo objetivo do primeiro código\n",
    "        \"n_estimators\": 1000,\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 150),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        \"random_state\": 123  # Garantindo reprodutibilidade\n",
    "    }\n",
    "\n",
    "    model_3 = XGBRegressor(**params)\n",
    "    model_3.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model_3.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhores hiperparâmetros:', study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo com os hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Após identificar os melhores hiperparâmetros através do processo de otimização com a biblioteca Optuna, esses parâmetros foram aplicados ao treinamento do modelo. O objetivo dessa nova etapa de treinamento é verificar se as otimizações resultaram em uma melhora perceptível na performance do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = XGBRegressor(objective='reg:pseudohubererror', random_state=123, colsample_bytree =0.6304272148495176, learning_rate =0.002729517529305024, max_depth= 80, n_estimators= 1000, subsample=0.8659933074934297, min_child_weight= 1)\n",
    "model_3.fit(X_train, y_train)\n",
    "predictions = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da performace do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Após o treinamento do modelo utilizando os hiperparâmetros otimizados, foi gerado um gráfico para visualizar a performance das previsões. Esse gráfico é necessário para compreender como as otimizações influenciaram o desempenho do modelo, fornecendo uma comparação visual entre os valores reais e os valores previstos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 3')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp; Assim, observa-se as seguintes métricas obtidas após os ajustes dos hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model_3, 'xgb_regressor_model3.pkl')\n",
    "# Load the model later (when needed)\n",
    "loaded_model_3 = joblib.load('xgb_regressor_model3.pkl')\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo do cluster 4 - XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo sem os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_4.drop(columns=['gasto','date'])  \n",
    "y = df_4['gasto'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "model_4 = XGBRegressor(objective='reg:pseudohubererror', random_state=123)\n",
    "\n",
    "model_4.fit(X_train, y_train)\n",
    "\n",
    "predictions = model_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas e gráficos da perfomace do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os valores reais vs previstos no conjunto de teste\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Gráfico dos valores reais vs valores previstos\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.6, label='Valores Previsto x Real')\n",
    "\n",
    "# Definindo os limites para as linhas de correspondência\n",
    "limite = [min(y_test.min(), predictions.min()), max(y_test.max(), predictions.max())]\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 0.75*np.array(limite), color='green', linestyle='--', label='Correspondência de -75%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 0.50*np.array(limite), color='orange', linestyle='--', label='Correspondência de -50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 75% (0.75)\n",
    "plt.plot(limite, 1.5*np.array(limite), color='green', linestyle='--', label='Correspondência de +50%')\n",
    "\n",
    "# Adicionando a linha diagonal de correspondencia de 50% (0.50)\n",
    "plt.plot(limite, 1.75*np.array(limite), color='orange', linestyle='--', label='Correspondência de +75%')\n",
    "\n",
    "# Linha de perfeita correspondência (y = x)\n",
    "plt.plot(limite, limite, color='red', linestyle='--', label='Perfeita correspondência (y=x)')\n",
    "\n",
    "plt.title('Valores Reais vs Valores Previstos no cluster 4')\n",
    "plt.xlabel('Consumo Real')\n",
    "plt.ylabel('Consumo Previsto')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as métricas de MAE\n",
    "print(f'Métrica MAE na base de teste: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de MSE\n",
    "print(f'Métrica MSE na base de teste: {mean_squared_error(y_test, predictions):.4f}')\n",
    "\n",
    "# Imprime as métricas de RMSE\n",
    "print(f'Métrica RMSE na base de teste: {np.sqrt(mean_squared_error(y_test, predictions)):.4f}')\n",
    "\n",
    "# Imprime o R²\n",
    "print(f'Métrica R² na base de teste: {r2_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model_4, 'xgb_regressor_model4.pkl')\n",
    "# Load the model later (when needed)\n",
    "loaded_model_4 = joblib.load('xgb_regressor_model4.pkl')\n",
    "# Predict using the loaded model\n",
    "predictions = loaded_model_4.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
