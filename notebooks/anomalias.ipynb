{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparação do notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça a leitura do dataframe desejado, ex: month_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/month_2.csv') # modifique de acordo com o desejado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando as colunas indesejadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['initialIndex', 'meterSN', 'meterSN','inputType', 'model', 'rssi', 'gatewayGeoLocation.alt', 'gatewayGeoLocation.lat', 'gatewayGeoLocation.long' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando a coluna de gasto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gain'] = df['gain'].fillna(1)\n",
    "df['medidor'] = df['pulseCount'] * df['gain']\n",
    "\n",
    "df['gasto'] = 0.0\n",
    "\n",
    "df = df.sort_values(by=['datetime', 'clientCode' ])\n",
    "\n",
    "df['gasto'] = df.groupby(['clientCode', 'clientIndex'])['medidor'].diff()\n",
    "\n",
    "df['gasto'] = df['gasto'].fillna(0)\n",
    "\n",
    "df = df.sort_values(by=[ 'clientCode', 'clientIndex','datetime'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando a coluna de gasto por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "df = df[df['gasto'] != 0]\n",
    "\n",
    "df = df.sort_values(by=['clientCode', 'clientIndex', 'datetime'])\n",
    "\n",
    "df['diferenca_tempo'] = df.groupby(['clientCode', 'clientIndex'])['datetime'].diff().dt.total_seconds().fillna(3600) / 3600\n",
    "\n",
    "df['gasto_por_hora'] = round(df['gasto'] / df['diferenca_tempo'], 10)\n",
    "\n",
    "df = df.drop(columns=['diferenca_tempo'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando as colunas que não são masi necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['medidor', 'gain', 'meterIndex', 'pulseCount', 'datetime', 'gasto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dataframe de anomalias feitos por analise básica do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_anomalies = df[df['gasto_por_hora'] < 0].copy()\n",
    "negative_anomalies['tipo_anomalia'] = 1\n",
    "\n",
    "positive_anomalies_list = []\n",
    "\n",
    "for (clientCode, clientIndex), group_df in df.groupby(['clientCode', 'clientIndex']):\n",
    "    mean = group_df['gasto_por_hora'].mean()\n",
    "    std_dev = group_df['gasto_por_hora'].std()\n",
    "\n",
    "    lower_bound = mean - 2 * std_dev\n",
    "    upper_bound = mean + 2 * std_dev\n",
    "\n",
    "    is_gasto_anomaly = (group_df['gasto_por_hora'] < lower_bound) | (group_df['gasto_por_hora'] > upper_bound)\n",
    "\n",
    "    group_gasto_anomalies = group_df[is_gasto_anomaly].copy()\n",
    "    group_gasto_anomalies['tipo_anomalia'] = 2\n",
    "\n",
    "    positive_anomalies_list.append(group_gasto_anomalies)\n",
    "\n",
    "positive_anomalies = pd.concat(positive_anomalies_list, ignore_index=True)\n",
    "\n",
    "anomalies_df = pd.concat([negative_anomalies, positive_anomalies], ignore_index=True)\n",
    "\n",
    "anomalies_df.to_csv('../data/anomalias.csv', index=False)\n",
    "\n",
    "anomalies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dataframe de anomalias por cliente feito por analise básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cliente_anomalies = anomalies_df.groupby(['clientCode', 'clientIndex']).size().reset_index(name='total_de_anomalias')\n",
    "\n",
    "for tipo in range(1, 3):\n",
    "    anomalias_tipo = anomalies_df[anomalies_df['tipo_anomalia'] == tipo].groupby(['clientCode', 'clientIndex']).size().reset_index(name=f'anomalia_tipo_{tipo}')\n",
    "    \n",
    "    df_cliente_anomalies = df_cliente_anomalies.merge(anomalias_tipo, on=['clientCode', 'clientIndex'], how='left')\n",
    "\n",
    "df_cliente_anomalies.fillna(0, inplace=True)\n",
    "\n",
    "df_cliente_anomalies = df_cliente_anomalies.sort_values(by=['anomalia_tipo_1', 'anomalia_tipo_2'], ascending=[False, False])\n",
    "\n",
    "gasto_count = df.groupby(['clientCode', 'clientIndex']).size().reset_index(name='quantidade_dados')\n",
    "\n",
    "df_cliente_anomalies = df_cliente_anomalies.merge(gasto_count, on=['clientCode', 'clientIndex'], how='left')\n",
    "\n",
    "df_cliente_anomalies['porcentagem_anomalia'] = df_cliente_anomalies['total_de_anomalias'] / df_cliente_anomalies['quantidade_dados']\n",
    "\n",
    "df_cliente_anomalies.to_csv('../data/anomalias_por_cliente.csv', index=False)\n",
    "\n",
    "df_cliente_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe de clientes anômalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegando somente os pontos com gastos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gasto_por_hora'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupando por clientCode e clientIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['clientCode', 'clientIndex']).agg(\n",
    "    media_gasto=('gasto_por_hora', 'mean'),\n",
    "    max_gasto=('gasto_por_hora', 'max'),\n",
    "    min_gasto=('gasto_por_hora', 'min'),\n",
    "    desvio_padrao=('gasto_por_hora', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando os valores NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o dataframe para rodar no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_sem_id = df.copy()\n",
    "df_sem_id = df.drop(columns=['clientCode', 'clientIndex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "svc_model_loaded = joblib.load('../data/svc_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando a coluna de cluster de acordo com o que foi previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pred = svc_model_loaded.predict(df_sem_id)\n",
    "\n",
    "df['cluster'] = cluster_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando a coluna de anomalia de acordo com os clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anomaly'] = ((df['cluster'] == 5) | (df['cluster'] == 6)).astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salva o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/anomaly_cliente.csv') #modifique o nome de acordo com o desejado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
