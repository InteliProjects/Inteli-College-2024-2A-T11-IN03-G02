{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from itertools import combinations\n",
    "import joblib\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Entendimento do dataframe pré-processado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Lendo o dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Entendendo o dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modificação do antigo dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Adição de colunas extras conforme a demanda dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;Adiciona coluna de gastos tendo em vista o feedback do cliente, pois, o meterIndex é um fator cumulativo, ou seja, sempre aumenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gain'] = df['gain'].fillna(1)\n",
    "df['medidor'] = df['pulseCount'] * df['gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gasto'] = 0.0\n",
    "\n",
    "df = df.sort_values(by=['datetime', 'clientCode' ])\n",
    "\n",
    "df['gasto'] = df.groupby(['clientCode', 'clientIndex'])['medidor'].diff()\n",
    "\n",
    "df['gasto'] = df['gasto'].fillna(0)\n",
    "\n",
    "df = df.sort_values(by=[ 'clientCode', 'clientIndex','datetime'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica se há números negativos na coluna gastos,\n",
    "já que a coluna gastos pelo número seguinte sempre ser maior que o anterior não deve ter números negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gastos_negativos = df[df['gasto'] < 0]\n",
    "print(gastos_negativos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Deletando as colunas que não são mais necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['meterIndex', 'inputType', 'rssi', 'Cocção + Aquecedor', 'Cocção + Caldeira', 'Aquecedor', 'Cocção', 'Caldeira', 'Cocção + Aquecedor + Piscina', 'condCode', 'Infinity V2', 'pulseCount', 'gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], unit='s')\n",
    "\n",
    "df = df[df['gasto'] != 0]\n",
    "\n",
    "df = df.sort_values(by=['clientCode', 'clientIndex', 'datetime'])\n",
    "\n",
    "df['diferenca_tempo'] = df.groupby(['clientCode', 'clientIndex'])['datetime'].diff().dt.total_seconds().fillna(3600) / 3600\n",
    "\n",
    "df['gasto_por_hora'] = round(df['gasto'] / df['diferenca_tempo'], 10)\n",
    "\n",
    "df = df.drop(columns=['diferenca_tempo'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['datetime'], unit='s').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['datetime', 'categoria', 'medidor', 'gasto', 'IG1K-L-v2', 'bairro'], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retirada de pontos outiliers, que podem influenciar negativamente no modelo e separação do DataFrame de treinamento e de teste.\n",
    "O DataFrame de treinamento corresponde aos meses de fevereiro até maio, enquanto o DataFrame de teste corresponde ao mês de junho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "percentil_baixo = np.percentile(df['gasto_por_hora'], 2.5)\n",
    "percentil_alto = np.percentile(df['gasto_por_hora'], 97.5)\n",
    "\n",
    "df_filtrado = df[(df['gasto_por_hora'] >= percentil_baixo) & (df['gasto_por_hora'] <= percentil_alto)]\n",
    "\n",
    "df_total = df_filtrado.copy()\n",
    "\n",
    "df_fev_maio = df_filtrado[(df_filtrado['date'].dt.month >= 2) & (df_filtrado['date'].dt.month <= 5)]\n",
    "\n",
    "df_junho = df_filtrado[df_filtrado['date'].dt.month >= 6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Agrupando os dataframes por clientes.\n",
    "Criando as colunas:\n",
    " - media_gasto\n",
    " - max_gasto\n",
    " - min_gasto\n",
    " - desvio_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treinamento = df_fev_maio.groupby(['clientCode', 'clientIndex']).agg(\n",
    "    media_gasto=('gasto_por_hora', 'mean'),\n",
    "    max_gasto=('gasto_por_hora', 'max'),\n",
    "    min_gasto=('gasto_por_hora', 'min'),\n",
    "    desvio_padrao=('gasto_por_hora', 'std')\n",
    ").reset_index()\n",
    "\n",
    "df_testes = df_junho.groupby(['clientCode', 'clientIndex']).agg(\n",
    "    media_gasto=('gasto_por_hora', 'mean'),\n",
    "    max_gasto=('gasto_por_hora', 'max'),\n",
    "    min_gasto=('gasto_por_hora', 'min'),\n",
    "    desvio_padrao=('gasto_por_hora', 'std')\n",
    ").reset_index()\n",
    "\n",
    "df_total = df_total.groupby(['clientCode', 'clientIndex']).agg(\n",
    "    media_gasto=('gasto_por_hora', 'mean'),\n",
    "    max_gasto=('gasto_por_hora', 'max'),\n",
    "    min_gasto=('gasto_por_hora', 'min'),\n",
    "    desvio_padrao=('gasto_por_hora', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treinamento = df_treinamento.dropna()\n",
    "df_testes = df_testes.dropna()\n",
    "df_total = df_total.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Visualização de como ficaram os novos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treinamento #dataframe para treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testes #dataframe para testagem do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Normalização do banco de dados e retirada das colunas clienteCode e clienteIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_kmeans_treinamento = df_treinamento.copy()\n",
    "df_kmeans_treinamento = df_kmeans_treinamento.drop(columns=['clientCode', 'clientIndex'])\n",
    "\n",
    "df_scaled_treinamento = scaler.fit_transform(df_kmeans_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Realiza a busca pelos melhores hiperparâmetros para o KMeans por meio do Random Search.\n",
    "Ao achar os melhores hiperparâmetros, o kmeans é gerado para separar o código por clusters (grupos) considerando semelhança entre os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "param_distributions = {'n_clusters': range(2, 10), 'init': ['k-means++', 'random'], 'n_init': [10, 20], 'max_iter': [300, 400]}\n",
    "kmeans = KMeans(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=kmeans, param_distributions=param_distributions, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(df_scaled_treinamento)\n",
    "\n",
    "best_kmeans = random_search.best_estimator_\n",
    "print(\"Melhores parâmetros:\", random_search.best_params_)\n",
    "\n",
    "y_predict = best_kmeans.predict(df_scaled_treinamento)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plota o gráfico dos clusters utilizando o PCA para reduzir a dimensionalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "pca_2d = PCA(n_components=2)\n",
    "df_pca_2d = pca_2d.fit_transform(df_scaled_treinamento)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "sns.scatterplot(x=df_pca_2d[:, 0], y=df_pca_2d[:, 1], hue=y_predict, s=100, alpha=0.75, \n",
    "                palette=\"Set1\", edgecolor='white', linewidth=0.8, ax=ax2)\n",
    "\n",
    "ax2.set_title(f\"2D Clusters: {best_kmeans.n_clusters}\")\n",
    "ax2.set_xlabel(\"Componente Principal 1\")\n",
    "ax2.set_ylabel(\"Componente Principal 2\")\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Plota os gráficos dos clusters para cada combinação de colunas possíveis. \n",
    "Isso é feito para ter uma melhor análise do comportamento dos clusters e identificar quais consideramos anômalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_treinamento['cluster'] = y_predict\n",
    "df_kmeans_treinamento['cluster'] = y_predict\n",
    "\n",
    "columns_to_plot = df_kmeans_treinamento.columns\n",
    "column_combinations = list(combinations(columns_to_plot, 2))\n",
    "\n",
    "for col_x, col_y in column_combinations:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    sns.scatterplot(x=df_kmeans_treinamento[col_x], y=df_kmeans_treinamento[col_y], hue=y_predict, \n",
    "                    palette=\"Set1\", s=100, alpha=0.75, edgecolor='white', linewidth=0.8)\n",
    "\n",
    "    plt.title(f\"Scatter Plot - {col_x} vs {col_y}\")\n",
    "    plt.xlabel(col_x)\n",
    "    plt.ylabel(col_y)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os gráficos, é possível perceber que os clusters 5 e 6 apresentam um comportamento mais anômalo. Isso se deve ao fato de serem os clusters com maior desvio padrão, além de apresentarem um gasto mínimo muito baixo e um gasto máximo muito alto, evidenciando uma grande variação no consumo. Esse comportamento é considerado estranho neste caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização do banco de dados e retirada das colunas clienteCode e clienteIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_kmeans_teste = df_testes.copy()\n",
    "df_kmeans_teste = df_kmeans_teste.drop(columns=['clientCode', 'clientIndex'])\n",
    "\n",
    "df_scaled_teste = scaler.transform(df_kmeans_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cálculo da distância de cada ponto do DataFrame de teste em relação aos centróides do KMeans gerado com o DataFrame de treinamento. \n",
    "Isso foi feito para adicionar a coluna de cluster ao DataFrame de teste, associando cada ponto ao centróide mais próximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "closest_clusters, distances = pairwise_distances_argmin_min(df_scaled_teste, best_kmeans.cluster_centers_)\n",
    "\n",
    "df_testes['cluster'] = closest_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando como ficaram os novos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_testes #dataframe para testes considerando a coluna de cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_treinamento #dataframe para treinamento considerando a coluna de cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Definindo o modelo supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirada das colunas clientCode, clientIndex e cluster, para gerar o modelo supervisionado. A coluna cluster é justamente retirada pois como já identificamos e rotulamos os perfis anômalos, a coluna de clusters não será mais necessária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_treino = df_treinamento.copy()\n",
    "df_treino = df_treino.drop(columns=['clientCode', 'clientIndex'])\n",
    "\n",
    "df_teste = df_testes.copy()\n",
    "df_teste = df_testes.drop(columns=['clientCode', 'clientIndex'])\n",
    "\n",
    "df_total_sem_id = df_total.copy()\n",
    "df_total_sem_id = df_total.drop(columns=['clientCode', 'clientIndex'])\n",
    "\n",
    "df_teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código realiza a otimização de hiperparâmetros para quatro modelos de classificação (Random Forest, Gradient Boosting, Regressão Logística e SVC) utilizando o Random Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_treino.drop(columns=['cluster'])\n",
    "y_train = df_treino['cluster']\n",
    "\n",
    "if 'cluster_pred' in df_teste.columns:\n",
    "    df_teste = df_teste.drop(columns=['cluster_pred'])\n",
    "\n",
    "X_test = df_teste.drop(columns=['cluster'])\n",
    "y_test = df_teste['cluster'] if 'cluster' in df_teste.columns else None\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVC': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "param_distributions = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "\n",
    "    random_search = RandomizedSearchCV(model, param_distributions[model_name], n_iter=10, cv=5, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    df_testes['cluster_pred'] = y_pred\n",
    "    \n",
    "    print(f\"\\n{model_name} - Melhores parâmetros: {random_search.best_params_}\")\n",
    "    if y_test is not None:\n",
    "        print(f\"Acurácia: {accuracy_score(y_test, y_pred)}\")\n",
    "        print(f\"Relatório de Classificação:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0','1', '2', '3', '4', '5', '6', '7'])\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f'Matriz de Confusão - {model_name}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Predições feitas, mas y_test não está disponível para calcular métricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após encontrar os melhores parâmetros, treina os modelos no conjunto de treino e faz previsões dos clusters no conjunto de teste, adicionando as previsões na coluna cluster_pred do DataFrame de teste. Por fim, avalia o desempenho do modelo calculando acurácia, exibindo o relatório de classificação e plotando a matriz de confusão para comparar predições com os rótulos reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando as matrizes de confusão, temos que, a partir dos dados de teste (1 mês da base referida), o melhor modelo é o SVC - bastante eficaz para problemas de classificação, especialmente quando o número de características (features) é alto, e é usado em diversas aplicações, como detecção de anomalias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Avaliação da importência das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.barh(X_train.columns[sorted_idx], result.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Importância\")\n",
    "plt.title(\"Importância das Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico de importância das features do modelo SVC destaca os seguintes pontos principais:\n",
    "\n",
    "1. **max_gasto**: A variável mais influente, indicando que gastos elevados são fortes sinais de anomalias.\n",
    "\n",
    "2. **desvio_padrao**: Também significativo, sugere que a variabilidade nos gastos é importante para identificar comportamentos atípicos.\n",
    "\n",
    "3. **media_gasto**: Tem um impacto menor, mas ainda relevante, mostrando que os gastos habituais podem estar relacionados a anomalias.\n",
    "\n",
    "4. **min_gasto**: Com a menor importância, indica que gastos mínimos não são determinantes para a detecção de anomalias.\n",
    "\n",
    "Em suma, os gastos máximos e a variabilidade são os principais fatores na identificação de anomalias, enquanto a média e o mínimo gasto têm menor relevância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_sem_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = best_models.get('SVC')\n",
    "\n",
    "cluster_pred = svc_model.predict(df_total_sem_id)\n",
    "\n",
    "df_total['cluster'] = cluster_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Adição da coluna anomaly nos DataFrames\n",
    "Como analisado no código anterior, os clusters 5 e 6 foram considerados anômalos. Portanto, os clientes que pertencem a esses clusters são classificados como anomalias, enquanto os demais são considerados normais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['anomaly'] = ((df_total['cluster'] == 5) | (df_total['cluster'] == 6)).astype(int)\n",
    "\n",
    "df_total.to_csv('../data/df_anomaly_cliente.csv')\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svc_model, 'svc_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
