{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de Dados e Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn import metrics\n",
    "import holidays\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_02 = pd.read_csv('../data/month_2.csv')\n",
    "mes_03 = pd.read_csv('../data/month_3.csv')\n",
    "mes_04 = pd.read_csv('../data/month_4.csv')\n",
    "mes_05 = pd.read_csv('../data/month_5.csv')\n",
    "mes_06 = pd.read_csv('../data/month_6.csv')\n",
    "cadastro = pd.read_csv('../data/informacao_cadastral.csv')\n",
    "\n",
    "meses = pd.concat([mes_02, mes_03, mes_04, mes_05, mes_06])\n",
    "\n",
    "df = pd.merge(meses, cadastro, on=['clientCode', 'clientIndex',], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa etapa é muito importante para garantir que os dados estejam prontos para serem utilizados no modelo de machine learning. Aqui, vamos tratar valores ausentes, converter tipos de dados, criar novas variáveis e fazer outras transformações necessárias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo colunas desnecessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['initialIndex', 'meterSN', 'cidade', 'contratacao', 'condIndex' ])\n",
    "df.drop(columns=['gatewayGeoLocation.alt','gatewayGeoLocation.lat', 'gatewayGeoLocation.long'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rssi'] = df['rssi'].fillna(0)\n",
    "\n",
    "for column in ['bairro', 'categoria', 'perfil_consumo', 'condCode']:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dados Meteorológicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adiciona features de dados meteorológicos ao dataset. Trazendo informações de temperatura, umidade, pressão atmosférica e direção do vento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando dados meteorológicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos = pd.read_csv('../data/generatedBy_react-csv.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo colunas desnecessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos = df_meteorologicos.drop(columns=['Radiacao (KJ/m²)','Hora (UTC)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando o nome das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos = df_meteorologicos.rename(columns={'Dir. Vento (m/s)': 'Dir. Vento (°)'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para preencher valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_valores_nulos(df, col_min, col_instant, col_max):\n",
    "\n",
    "    df[col_min].fillna(df[col_instant], inplace=True)\n",
    "    df[col_min].fillna(df[col_max], inplace=True)\n",
    "\n",
    "    df[col_instant].fillna(df[col_min], inplace=True)\n",
    "    df[col_instant].fillna(df[col_max], inplace=True)\n",
    "\n",
    "    df[col_max].fillna(df[col_instant], inplace=True)\n",
    "    df[col_max].fillna(df[col_min], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tratar_valores_nulos(df_meteorologicos,'Temp. Min. (C)', 'Temp. Ins. (C)', 'Temp. Max. (C)')\n",
    "tratar_valores_nulos(df_meteorologicos,'Umi. Min. (%)', 'Umi. Ins. (%)', 'Umi. Max. (%)')\n",
    "tratar_valores_nulos(df_meteorologicos,'Pto Orvalho Min. (C)', 'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)')\n",
    "tratar_valores_nulos(df_meteorologicos,'Pressao Min. (hPa)', 'Pressao Ins. (hPa)', 'Pressao Max. (hPa)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando o padrão de valores de \",\" para \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Temp. Ins. (C)', 'Temp. Max. (C)', 'Temp. Min. (C)',\n",
    "       'Umi. Ins. (%)', 'Umi. Max. (%)', 'Umi. Min. (%)',\n",
    "       'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)', 'Pto Orvalho Min. (C)',\n",
    "       'Pressao Ins. (hPa)', 'Pressao Max. (hPa)', 'Pressao Min. (hPa)',\n",
    "       'Vel. Vento (m/s)', 'Dir. Vento (°)', 'Raj. Vento (m/s)',\n",
    "       'Chuva (mm)']:\n",
    "    df_meteorologicos[column] = pd.to_numeric(df_meteorologicos[column].str.replace(',', '.'), errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifica se os valores foram alterados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Vel. Vento (m/s)', 'Dir. Vento (°)', 'Raj. Vento (m/s)','Chuva (mm)']:\n",
    "        df_meteorologicos[column].fillna(df_meteorologicos[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a data como índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos['Data'] = pd.to_datetime(df_meteorologicos['Data'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupando os dados por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos = round(df_meteorologicos.groupby(df_meteorologicos['Data'].dt.date, as_index=False).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando o nome de \"Data\" para \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteorologicos = df_meteorologicos.rename(columns={'Data': 'date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Códificação de variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa etapa é necessária para transformar as variáveis categóricas em numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códificando variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder = LabelEncoder()\n",
    "\n",
    "df['clientCode'] = LabelEncoder.fit_transform(df['clientCode'])\n",
    "df['bairro'] = LabelEncoder.fit_transform(df['bairro'])\n",
    "df['categoria'] = LabelEncoder.fit_transform(df['categoria'])\n",
    "df['condCode'] = LabelEncoder.fit_transform(df['condCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type_mapping = {\n",
    "    'leituraRemota': 0,\n",
    "    'DI1': 1,\n",
    "    'DI2': 2,\n",
    "    'DI3': 2,\n",
    "    'DI4': 4,\n",
    "    'DI5': 5,\n",
    "    'DI6': 6,\n",
    "    'DI7': 7,\n",
    "    'DI8': 8,\n",
    "}\n",
    "\n",
    "df['inputType'] = df['inputType'].map(input_type_mapping)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códificando a coluna \"model\" com One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codificadorModel = OneHotEncoder(cols=['model'])\n",
    "df = codificadorModel.fit_transform(df)\n",
    "df.rename(columns={'model_1': 'IG1K-L-v2', 'model_2': 'Infinity V2'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo caracteres especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moda = df['perfil_consumo'].mode()[0]\n",
    "df = df.replace('-', moda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Códificando a coluna \"perfil_consumo\" com One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codificadorPerfilConsumo = OneHotEncoder(cols=['perfil_consumo'])\n",
    "df = codificadorPerfilConsumo.fit_transform(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auxiliar = pd.merge(meses, cadastro, on=['clientCode', 'clientIndex',], how='left')\n",
    "\n",
    "colunasPerfilConsumo = df[['perfil_consumo_1', 'perfil_consumo_2', 'perfil_consumo_3', \n",
    "                             'perfil_consumo_4', 'perfil_consumo_5', 'perfil_consumo_6']]\n",
    "\n",
    "indices = []\n",
    "\n",
    "for coluna in colunasPerfilConsumo:\n",
    "    indice = df[df[coluna] == 1].index[0] if not df[df[coluna] == 1].empty else None\n",
    "    indices.append(indice)\n",
    "\n",
    "valorIndice = []\n",
    "\n",
    "for indice in indices:\n",
    "    valor = df_auxiliar.loc[indice,'perfil_consumo']\n",
    "    valorIndice.append(valor)\n",
    "\n",
    "df = df.rename(columns={'perfil_consumo_1': valorIndice[0], 'perfil_consumo_2': valorIndice[1], 'perfil_consumo_3': valorIndice[2], 'perfil_consumo_4': valorIndice[3], 'perfil_consumo_5': valorIndice[4], 'perfil_consumo_6': valorIndice[5] })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature \"Dia da Semana\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa feature é importante para identificar se o dia da semana influencia no consumo de energia. Como a variável \"data\" está no formato datetime, podemos extrair o dia da semana, sendo 0 = segunda-feira e 6 = domingo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'data_completa' para o tipo datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Criar a coluna apenas com a hora\n",
    "df['hora'] = df['datetime'].dt.strftime('%H').astype(int)\n",
    "\n",
    "# Criar a coluna apenas com o mes\n",
    "df['mes'] = df['datetime'].dt.strftime('%m').astype(int)\n",
    "\n",
    "# Criar a coluna com o dia da semana\n",
    "df['dia_da_semana'] = df['datetime'].dt.weekday\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature \"Consumo por dia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa feature é importante para identificar o consumo de energia por dia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo valores faltantes no \"gain\" com 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gain'] = df['gain'].fillna(1)\n",
    "df['medidor'] = df['pulseCount'] * df['gain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a feature \"gasto\", que é a multiplicação do \"consumo\" pelo \"gain\", agrupando por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gasto'] = 0.0\n",
    "\n",
    "df = df.sort_values(by=['clientCode', 'datetime'])\n",
    "\n",
    "df['gasto'] = df.groupby(['clientCode', 'clientIndex'])['medidor'].diff()\n",
    "\n",
    "df['gasto'] = df['gasto'].fillna(0)\n",
    "\n",
    "resultado = df\n",
    "\n",
    "df = df.sort_values(by=['datetime'])\n",
    "\n",
    "print(df[['clientCode', 'medidor', 'gasto', 'datetime']])\n",
    "\n",
    "print(df[['clientCode', 'medidor', 'gasto', 'datetime']])\n",
    "print(\"\\nLinhas com 'gasto' diferente de 0:\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['clientCode', 'datetime'], inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'datetime' para o formato de data\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Criar uma nova coluna 'date' contendo apenas a df (sem a hora)\n",
    "df['date'] = df['datetime'].dt.date\n",
    "\n",
    "# Agrupar por 'clientCode' e 'date' e somar o 'gasto' para obter o consumo diário\n",
    "daily_consumption = df.groupby(['clientCode', 'clientIndex', 'date'])['gasto'].sum().reset_index()\n",
    "\n",
    "# daily_consumption['dia_da_semana'] = pd.to_datetime(df['date']).dt.weekday\n",
    "# daily_consumption['mes'] = pd.to_datetime(df['date']).dt.month\n",
    "# daily_consumption['hora'] = pd.to_datetime(df['date']).dt.hour\n",
    "\n",
    "# Colunas\n",
    "colunasDf = ['clientCode', 'clientIndex', 'date', 'hora', 'dia_da_semana', 'mes', 'bairro', 'categoria', 'IG1K-L-v2', 'Infinity V2', 'inputType', 'medidor', 'feriado']\n",
    "\n",
    "df = pd.merge(daily_consumption, \n",
    "                df[colunasDf].drop_duplicates(subset=['clientCode','clientIndex', 'date']),\n",
    "                on=['clientCode','clientIndex', 'date'],\n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Features \"Feriados\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature que identifica se o dia é feriado ou não. Ou seja, se o dia é um feriado, o valor é 1, caso contrário, o valor é 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a lista de feriados para o Brasil\n",
    "br_holidays = holidays.Brazil()\n",
    "\n",
    "# Converter a coluna 'datetime' para o formato datetime do pandas\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Criar uma nova coluna 'feriado', onde 1 indica que a data é feriado e 0 indica que não é\n",
    "df['feriado'] = df['datetime'].dt.date.apply(lambda x: 1 if x in br_holidays else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Feature \"Condições Climáticas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junta as features de temperatura, umidade, pressão atmosférica e direção do vento ao dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado = pd.merge(df, df_meteorologicos, on='date', how='left')\n",
    "df_atualizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Feature \"Gasto por hora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa feature é importante para identificar o consumo por hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado['datetime'] = pd.to_datetime(df_atualizado['date'].astype(str) + ' ' + df_atualizado['hora'].astype(str) + ':00')\n",
    "\n",
    "# Filtrar onde 'gasto' não é zero\n",
    "df_atualizado = df_atualizado[df_atualizado['gasto'] != 0]\n",
    "\n",
    "# Ordenar os dados\n",
    "df_atualizado = df_atualizado.sort_values(by=['clientCode', 'clientIndex', 'datetime'])\n",
    "\n",
    "# Calcular a diferença de tempo em horas\n",
    "df_atualizado['diferenca_tempo'] = df_atualizado.groupby(['clientCode', 'clientIndex'])['datetime'].diff().dt.total_seconds().fillna(3600) / 3600\n",
    "\n",
    "# Calcular o gasto por hora\n",
    "df_atualizado['gasto_por_hora'] = round(df_atualizado['gasto'] / df_atualizado['diferenca_tempo'], 10)\n",
    "\n",
    "# Remover a coluna de diferença de tempo\n",
    "df_atualizado = df_atualizado.drop(columns=['diferenca_tempo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado = df_atualizado.drop(columns=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Exportando o dataset para o usar no modelo de machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado.to_csv('../data/df_atualizado.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
